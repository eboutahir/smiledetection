{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Smile Detector\n",
    "\n",
    "Using a CNN and OpenCV we will create a real-time smile detector which we can deploy through the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the smile detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bouta\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import keras\n",
    "from lenet import LeNet as LeNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# initialize the list of data and labels\n",
    "data = []\n",
    "labels = []\n",
    "# Smiling Images - read data and label\n",
    "directory = \"SmileCNN-master\\\\SMILEsmileD-master\\\\SMILEs\\\\positives\\\\positives7\"\n",
    "for imagePath in os.listdir(directory):\n",
    "    if imagePath.endswith(\".jpg\"): \n",
    "        image = cv2.imread(directory + \"\\\\\" + imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = imutils.resize(image, width=28)\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(\"smiling\")\n",
    "\n",
    "# Not Smiling - read data and label\n",
    "directory = \"SmileCNN-master\\\\SMILEsmileD-master\\\\SMILEs\\\\negatives\\\\negatives7\"\n",
    "for imagePath in os.listdir(directory):\n",
    "    if imagePath.endswith(\".jpg\"): \n",
    "        image = cv2.imread(directory + \"\\\\\" + imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = imutils.resize(image, width=28)\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(\"not_smiling\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Scale the raw pixel intensities to the range [0,1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "le = preprocessing.LabelEncoder().fit(labels)\n",
    "labels = tf.keras.utils.to_categorical(le.transform(labels), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de classTotals & classWeight\n",
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = classTotals.max() / classTotals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9475. 3690.]\n",
      "[1.         2.56775068]\n"
     ]
    }
   ],
   "source": [
    "print (classTotals)\n",
    "print (classWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# partition the data using 80% for training and 20% for testing\n",
    "(trainX, testX, trainY, testY) = model_selection.train_test_split(data, labels, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=28, height=28, depth=1, classes=2)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 10532 samples, validate on 2633 samples\n",
      "Epoch 1/15\n",
      "10532/10532 [==============================] - 42s 4ms/step - loss: 0.3931 - acc: 0.8221 - val_loss: 0.2643 - val_acc: 0.8899\n",
      "Epoch 2/15\n",
      "10532/10532 [==============================] - 43s 4ms/step - loss: 0.2716 - acc: 0.8905 - val_loss: 0.2517 - val_acc: 0.9070\n",
      "Epoch 3/15\n",
      "10532/10532 [==============================] - 36s 3ms/step - loss: 0.2478 - acc: 0.9008 - val_loss: 0.2259 - val_acc: 0.9134\n",
      "Epoch 4/15\n",
      "10532/10532 [==============================] - 35s 3ms/step - loss: 0.2301 - acc: 0.9097 - val_loss: 0.2297 - val_acc: 0.9104\n",
      "Epoch 5/15\n",
      "10532/10532 [==============================] - 35s 3ms/step - loss: 0.2127 - acc: 0.9166 - val_loss: 0.2211 - val_acc: 0.9161\n",
      "Epoch 6/15\n",
      "10532/10532 [==============================] - 36s 3ms/step - loss: 0.2117 - acc: 0.9159 - val_loss: 0.2174 - val_acc: 0.9138\n",
      "Epoch 7/15\n",
      "10532/10532 [==============================] - 41s 4ms/step - loss: 0.1973 - acc: 0.9255 - val_loss: 0.2074 - val_acc: 0.9164\n",
      "Epoch 8/15\n",
      "10532/10532 [==============================] - 38s 4ms/step - loss: 0.1802 - acc: 0.9339 - val_loss: 0.2196 - val_acc: 0.9157\n",
      "Epoch 9/15\n",
      "10532/10532 [==============================] - 44s 4ms/step - loss: 0.1686 - acc: 0.9360 - val_loss: 0.2093 - val_acc: 0.9164\n",
      "Epoch 10/15\n",
      "10532/10532 [==============================] - 37s 4ms/step - loss: 0.1623 - acc: 0.9376 - val_loss: 0.2094 - val_acc: 0.9138\n",
      "Epoch 11/15\n",
      "10532/10532 [==============================] - 37s 4ms/step - loss: 0.1479 - acc: 0.9448 - val_loss: 0.2254 - val_acc: 0.9119\n",
      "Epoch 12/15\n",
      "10532/10532 [==============================] - 41s 4ms/step - loss: 0.1357 - acc: 0.9485 - val_loss: 0.2419 - val_acc: 0.9092\n",
      "Epoch 13/15\n",
      "10532/10532 [==============================] - 37s 4ms/step - loss: 0.1287 - acc: 0.9501 - val_loss: 0.2216 - val_acc: 0.9214\n",
      "Epoch 14/15\n",
      "10532/10532 [==============================] - 42s 4ms/step - loss: 0.1155 - acc: 0.9546 - val_loss: 0.2593 - val_acc: 0.9176\n",
      "Epoch 15/15\n",
      "10532/10532 [==============================] - 39s 4ms/step - loss: 0.1037 - acc: 0.9612 - val_loss: 0.2443 - val_acc: 0.9149\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "not_smiling       0.95      0.93      0.94      1871\n",
      "    smiling       0.83      0.89      0.86       762\n",
      "\n",
      "avg / total       0.92      0.91      0.92      2633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mx\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(mx.classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Running the smile detector in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bouta\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:305: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import imutils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# load the face detector casscade and smile detector CNN\n",
    "model = load_model(\"face_recognition_model.H5\")\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# grab the reference to the webcam\n",
    "camera = cv2.VideoCapture(0)\n",
    "print (camera.isOpened ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\n",
    "    \n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    # resize the frame, convert it to grayscale, and then clone the\n",
    "    # original frame so we can draw on it later in the program\n",
    "    frame = imutils.resize(frame, width=300)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frameClone = frame.copy()\n",
    "\n",
    "    rects = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    # loop over the face bounding boxes\n",
    "    for (fX, fY, fW, fH) in rects:\n",
    "        # extract the ROI (region of interst) of the face from the grayscale image,\n",
    "        # resize it to a fixed 28x28 pixels, and then prepare the\n",
    "        # ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (28, 28))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "        \n",
    "        # determine the probabilities of both \"smiling\" and \"not\n",
    "        # smiling\", then set the label accordingly\n",
    "        (notSmiling, smiling) = model.predict(roi)[0]\n",
    "        if smiling > notSmiling:\n",
    "            label = \"Smiling\" \n",
    "        else:\n",
    "            label = \"Not Smiling\"\n",
    "\n",
    "        # display the label and bounding box rectangle on the output\n",
    "        # frame\n",
    "        cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "        (0, 0, 255), 2)\n",
    "\n",
    "        # show our detected faces along with smiling/not smiling labels\n",
    "        cv2.imshow(\"Face\", frameClone)\n",
    "\n",
    "        # if the ’q’ key is pressed, stop the loop\n",
    "        if cv2.waitKey(1) or 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
